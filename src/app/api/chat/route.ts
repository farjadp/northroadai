// ============================================================================
// ğŸ“ Hardware Source: src/app/api/chat/route.ts
// ğŸ•’ Date: 2025-11-30
// ğŸ§  Version: v7.0 (Uncensored + Chat History Support)
// ----------------------------------------------------------------------------
// âœ… Fixes:
// 1. Adds 'safetySettings' to prevent "I cannot answer" errors on Visa/Legal topics.
// 2. Injects 'history' into the prompt so AI remembers context.
// 3. Keeps Smart Model Selection.
// ============================================================================

import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import { NextResponse } from "next/server";
import { KnowledgeService } from "@/lib/api/knowledge";
import { UserService } from "@/lib/user-service";
import { getAgentById, getDefaultAgent } from "@/lib/agents";

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

export async function POST(req: Request) {
  try {
    // Ø¯Ø±ÛŒØ§ÙØª history Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øª
    const { message, startupContext, fileData, agentId, userId, history } = await req.json();

    // 1. Validate Access
    const requestedAgentId = agentId || "navigator";
    if (userId && requestedAgentId !== "navigator") {
      const hasAccess = await UserService.checkAgentAccess(userId, requestedAgentId);
      if (!hasAccess) {
        return NextResponse.json({ error: "Access Denied." }, { status: 403 });
      }
    }

    // 2. Setup Agent
    const agent = getAgentById(requestedAgentId) || getDefaultAgent();

    // 3. Smart Model Selection
    let targetModel = "gemini-2.0-flash"; 
    try {
        const listReq = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${process.env.GEMINI_API_KEY}`);
        const listData = await listReq.json();
        if (listData.models) {
            const names = listData.models.map((m: any) => m.name);
            const priorities = ["models/gemini-2.0-flash", "models/gemini-2.5-flash", "models/gemini-1.5-flash"];
            const found = priorities.find(p => names.includes(p));
            if (found) targetModel = found.replace("models/", ""); 
        }
    } catch (e) {}

    // âš ï¸ SAFETY SETTINGS (Ø­ÛŒØ§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª ÙˆÛŒØ²Ø§ Ùˆ Ø­Ù‚ÙˆÙ‚ÛŒ)
    const safetySettings = [
        { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
    ];

    const model = genAI.getGenerativeModel({ 
        model: targetModel,
        safetySettings: safetySettings 
    });

    // 4. RAG Layers
    const globalDocs = await KnowledgeService.getGlobalDocs();
    let userDocs: any[] = [];
    if (userId) userDocs = await KnowledgeService.getUserDocs(userId);

    // 5. Construct Payload
    const contentParts: any[] = [];

    // Inject Files (RAG)
    [...globalDocs, ...userDocs].forEach((doc: any) => {
        if (doc.fileUri) contentParts.push({ fileData: { mimeType: doc.mimeType, fileUri: doc.fileUri } });
    });
    if (fileData?.fileUri) {
        contentParts.push({ fileData: { mimeType: fileData.mimeType, fileUri: fileData.fileUri } });
    }

    // Inject Text Prompt
    const systemInstruction = `
${agent.systemPrompt}

=== CONTEXT & MEMORY ===
1. STARTUP DNA: ${startupContext ? JSON.stringify(startupContext) : "None"}
2. GLOBAL KNOWLEDGE: Use attached docs as primary truth.
    `;

    // Ø³Ø§Ø®ØªØ§Ø± Ø¬Ø¯ÛŒØ¯: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø¨Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª
    let fullConversation = systemInstruction + "\n\n=== CONVERSATION HISTORY ===\n";
    
    // Ø§Ú¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù† (Ø­Ø¯Ø§Ú©Ø«Ø± Ûµ Ù¾ÛŒØ§Ù… Ø¢Ø®Ø± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù¾Ø± Ø´Ø¯Ù† ØªÙˆÚ©Ù†)
    if (history && Array.isArray(history)) {
        history.slice(-5).forEach((msg: any) => {
            if (msg.role !== 'system') {
                fullConversation += `${msg.role === 'user' ? 'User' : 'AI'}: ${msg.content}\n`;
            }
        });
    }

    // Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯
    fullConversation += `User: ${message}\nAI:`;

    contentParts.push({ text: fullConversation });

    // 6. Generate
    console.log(`ğŸš€ Sending to ${targetModel} (With History & Safety Fix)`);
    const result = await model.generateContent(contentParts);
    const response = await result.response;
    const text = response.text();

    return NextResponse.json({ reply: text });

  } catch (error: any) {
    console.error("âŒ AI Error:", error.message);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}